---
title: "Summarization & Aggregation "
---

![Summarizationand Aggregation Jp](/images/SummarizationandAggregation.jpg)

The Summarization and Aggregation template enhances the basic summarization workflow by integrating Prompt Optimization and LLMC Executor capabilities.

<Note>
  This template enables you to upload documents, generate summaries, automatically optimize prompts, and evaluate the best-performing versions, all within one seamless LLM Controls workflow.
</Note>

## Prerequisites

1. An OpenAI API Key
2.  A structured document (PDF) for upload
3.  Basic familiarity with LLM Controls Flows

## Create the Advanced Summarization Flow

### 1. Upload a File

From the File component:

1. Upload your document (PDF format supported)
2. This component outputs both raw and parsed data
3. Output is automatically passed to the Parser component

### 2. Parse the Document

The Parser component converts uploaded content into plain text.

**Mode**: Parser

**Template**: Define how content is extracted (e.g., Text: text)\
This ensures your data is clean and ready for prompting

**Optimize the Summarization Prompt**

Use the Prompt Optimizer Flow to automatically refine your prompt.

1. Input a summarization task, such as:\
   **“Summarize uploaded documents into concise, professional summaries.”**
2. The optimizer generates **multiple prompt variations, test cases, and evaluation metrics.**
3. Outputs include ranked prompts based on clarity, effectiveness, and consistency.

<Note>
  Click the Prompt Optimizer Flow node in the workspace to open and run this optimization process.
</Note>

### 4. Execute with LLMC Executor

\
The LLMC Executor allows you to run the best-performing prompts with a chosen AI model.

1. **Model Selection**: Choose from GPT models (e.g., gpt-4o)
2. **Prompt Selection:** Pick from optimized prompts generated earlier
3. **API Key:** Enter your valid OpenAI key in the custom_api_key field

Then click Run to execute and generate the summarized output.

### 5. View the Summary Output

The Summary Output component displays the final, aggregated summary in a clean text format.\
You can review, copy, or export it directly from the Playground.

## Modify or Extend

1. To change the summarization style, open the Prompt template and adjust the tone or persona **(e.g., “Write an executive summary” or “Summarize in bullet points”).**
2. You can chain additional evaluation nodes for advanced comparison of results.
3. Use the **Results leaderboard** in the optimizer to monitor which prompt performs best.

## Configuration Checklist

| Setting               | Description                                       |
| :-------------------- | :------------------------------------------------ |
| OpenAI API Key        | Required to connect to GPT models                 |
| File Upload           | Input document (PDF)                              |
| Parser Template       | Controls how text is extracted                    |
| Prompt Optimizer Flow | Generates, evaluates, and ranks prompt variations |
| LLMC Executor         | Runs prompts with the chosen model                |
| Summary Output        | Displays the final summarized result              |

##   Use Cases

1. Generate executive summaries from lengthy reports
2. Compare and benchmark multiple summarization prompts
3. Automate evaluation of summarization quality
4. Build adaptive summarization pipelines for research or business data

## Built With

1. LLM Controls Framework
2. Prompt Optimizer Flow
3. LLMC Executor
4. OpenAI GPT Models

Streamline your summarization process with intelligent optimization and automated evaluation.